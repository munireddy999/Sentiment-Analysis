{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection and Preprocessing"
      ],
      "metadata": {
        "id": "tw1YkHaDGzNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Read the data with the correct encoding\n",
        "data = pd.read_csv('sentiment_dataset.csv', encoding='latin1')  # replace with the correct encoding\n",
        "\n",
        "# Fill missing values with an empty string\n",
        "data['text'].fillna('', inplace=True)\n",
        "\n",
        "# Convert all entries to strings\n",
        "data['text'] = data['text'].astype(str)\n",
        "\n",
        "# Text Cleaning Function\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])  # Remove stopwords\n",
        "    return text\n",
        "\n",
        "data['cleaned_text'] = data['text'].apply(preprocess_text)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_text'], data['sentiment'], test_size=0.2, random_state=42)\n",
        "\n",
        "#\n"
      ],
      "metadata": {
        "id": "tRaNiwnfA2xh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Extraction\n",
        "\n",
        "Bag-of-Words\n"
      ],
      "metadata": {
        "id": "AsLHbGJkBXAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(max_features=5000)\n",
        "X_train_bow = vectorizer.fit_transform(X_train).toarray()\n",
        "X_test_bow = vectorizer.transform(X_test).toarray()\n"
      ],
      "metadata": {
        "id": "lvZn833lBbt4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Training\n",
        "\n",
        "Bag-of-Words with Logistic Regression"
      ],
      "metadata": {
        "id": "49SX4KoFHbfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure there are no NaNs in the split data\n",
        "X_train = X_train.fillna('')\n",
        "X_test = X_test.fillna('')\n",
        "y_train = y_train.fillna(data['sentiment'].mode()[0])\n",
        "y_test = y_test.fillna(data['sentiment'].mode()[0])\n",
        "\n",
        "# Vectorizer (Bag-of-Words)\n",
        "vectorizer = CountVectorizer(max_features=5000)\n",
        "X_train_bow = vectorizer.fit_transform(X_train).toarray()\n",
        "X_test_bow = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "# Ensure there are no NaNs in the vectorized data\n",
        "X_train_bow = np.nan_to_num(X_train_bow)\n",
        "X_test_bow = np.nan_to_num(X_test_bow)\n",
        "\n",
        "# Model (Logistic Regression)\n",
        "model_bow = LogisticRegression()\n",
        "model_bow.fit(X_train_bow, y_train)\n",
        "\n",
        "y_pred_bow = model_bow.predict(X_test_bow)\n"
      ],
      "metadata": {
        "id": "HBhRfETmB6NS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Bag-of-Words Accuracy:\", accuracy_score(y_test, y_pred_bow))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_bow))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZn6xdKCEZof",
        "outputId": "ebc6d8d7-f0d5-40e4-cc74-0ae26cb40ccd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag-of-Words Accuracy: 0.6998961578400831\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.77      0.37      0.50       226\n",
            "     neutral       0.69      0.89      0.78       526\n",
            "    positive       0.70      0.58      0.63       211\n",
            "\n",
            "    accuracy                           0.70       963\n",
            "   macro avg       0.72      0.61      0.64       963\n",
            "weighted avg       0.71      0.70      0.68       963\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the Model to Predict Sentiment of New Examples"
      ],
      "metadata": {
        "id": "DiHDqtaFHoYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess a new example\n",
        "def preprocess_and_vectorize(text, vectorizer):\n",
        "    cleaned_text = preprocess_text(text)\n",
        "    vectorized_text = vectorizer.transform([cleaned_text]).toarray()\n",
        "    return vectorized_text\n",
        "\n",
        "# Example texts from the dataset to analyze sentiment\n",
        "example_texts = [\n",
        "    \"I love this product! It works really well.\",\n",
        "    \"This is the worst service I have ever received.\",\n",
        "    \"The product is okay, nothing special.\"\n",
        "]\n",
        "\n",
        "# Predict the sentiment of the example texts\n",
        "for text in example_texts:\n",
        "    vectorized_text = preprocess_and_vectorize(text, vectorizer)\n",
        "    sentiment = model_bow.predict(vectorized_text)\n",
        "    print(f\"Text: {text}\\nPredicted Sentiment: {sentiment[0]}\\n\")\n",
        "\n",
        "# Predict the sentiment of some texts from the dataset\n",
        "for i in range(5):\n",
        "    text = data['text'].iloc[i]\n",
        "    cleaned_text = preprocess_text(text)\n",
        "    vectorized_text = vectorizer.transform([cleaned_text]).toarray()\n",
        "    sentiment = model_bow.predict(vectorized_text)\n",
        "    print(f\"Text: {text}\\nPredicted Sentiment: {sentiment[0]}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f46qZjmEGV8x",
        "outputId": "3e8dfeee-1945-4b31-e24f-778b3b538821"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: I love this product! It works really well.\n",
            "Predicted Sentiment: positive\n",
            "\n",
            "Text: This is the worst service I have ever received.\n",
            "Predicted Sentiment: neutral\n",
            "\n",
            "Text: The product is okay, nothing special.\n",
            "Predicted Sentiment: neutral\n",
            "\n",
            "Text: Last session of the day  http://twitpic.com/67ezh\n",
            "Predicted Sentiment: neutral\n",
            "\n",
            "Text:  Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).\n",
            "Predicted Sentiment: positive\n",
            "\n",
            "Text: Recession hit Veronique Branquinho, she has to quit her company, such a shame!\n",
            "Predicted Sentiment: negative\n",
            "\n",
            "Text:  happy bday!\n",
            "Predicted Sentiment: positive\n",
            "\n",
            "Text:  http://twitpic.com/4w75p - I like it!!\n",
            "Predicted Sentiment: neutral\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "phHOYVzoGWds"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}